<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="参考资料： [Xilinx&#x2F;Vitis-AI-Tutorials (github.com)](https:&#x2F;&#x2F;github.com&#x2F;Xilinx&#x2F;Vitis-AI-Tutorials “Xilinx&#x2F;Vitis-AI-Tutorials (github.com)“) Xilinx&#x2F;Vitis-AI: Vitis AI is Xilinx’s development s">
<meta property="og:type" content="article">
<meta property="og:title" content="Vitis AI——FPGA学习笔记">
<meta property="og:url" content="http://example.com/2024/03/29/Vitis%20AI%E2%80%94%E2%80%94FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="Switch">
<meta property="og:description" content="参考资料： [Xilinx&#x2F;Vitis-AI-Tutorials (github.com)](https:&#x2F;&#x2F;github.com&#x2F;Xilinx&#x2F;Vitis-AI-Tutorials “Xilinx&#x2F;Vitis-AI-Tutorials (github.com)“) Xilinx&#x2F;Vitis-AI: Vitis AI is Xilinx’s development s">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/089f9efe7c54689a339a571239a84873.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/966474c137754c658fddaa07152e7ef2.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/319a2ebc600fdfb819856d52d5825acc.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/93def47e1072cf25c9fb7e564d9ac777.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/bc05d626369cb12f1b1b386fad291dfc.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/acb9834ffdad75aafa209db3944d7929.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/b926c0530c9f863597c101da17b84dd2.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/7632c574e72b01f31355845825ac6439.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/959557dd80a7f6cf4d928cceb75051d3.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/0508c091f64853b67804b2e760e60cbb.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/3caf388ba1b35f2a14b2243c95dc133c.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/999d2443c9fa5ace609d9ea94ced32fa.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/7830ed03ef207f14e4a19700168625d9.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/fd38dd26c8c57234f377f0f7a4a2ef48.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/5558aa103e0c00df512de7552ebe3804.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/8bd66f3a8c93d2eb320e9af0f1109b3c.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/18e33f756df780499701f1488563de29.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/8913598ae8b0c899f6a709062fe876f9.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/32b5b070bc91e1a49bc4d0cf742becc9.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/d0f0f5995489ccc5498b68acb9a6ac56.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/3fde56db0b1e14a450d2f3f07ce98f82.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/17de1dceb4e74e034696eb3b16af2272.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/53bfce013f7c4c2e53486eb49cae2149.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/00f5736efd94ea115591a8121f7171b4.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/1a916ce4ff8de0d37df1060bec900bd9.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/c9a7d62a708af32a1de4b5d1c059a76e.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/13689caf7d2c1dcba28ba1b59e594a71.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/154c0219b2383c095a676e4a40d64715.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/38b92c92fb4b1a06262e88117770e500.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/4a57b4d4b3f8c4bcd95910f16c04e505.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/a5c9e1dc7906295e163c8989b3a3b743.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/030fa826ada83d08a466bb23919680bc.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/9d34d43f9036308c8f83f589b763afd2.jpeg">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/b4e03ee0be4436f378980db2d44681b1.jpeg">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/2035fe160556f3713512b51266287de1.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/d38f0ab41704bb97f91f371d5b4c3cfd.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/4c32c7a9a74429a18ef81f04ae3638c1.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/6c5bf2b5b0093972699eb12988ab59d9.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/478de52c0e6c34207461eb523f74eb5a.png">
<meta property="og:image" content="https://i-blog.csdnimg.cn/blog_migrate/781bf68946aadd0ca2d81fe1be31e3f9.png">
<meta property="article:published_time" content="2024-03-29T09:29:19.000Z">
<meta property="article:modified_time" content="2025-02-08T03:54:05.393Z">
<meta property="article:author" content="SWQ">
<meta property="article:tag" content="fpga开发">
<meta property="article:tag" content="学习">
<meta property="article:tag" content="笔记">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i-blog.csdnimg.cn/blog_migrate/089f9efe7c54689a339a571239a84873.png">

<link rel="canonical" href="http://example.com/2024/03/29/Vitis%20AI%E2%80%94%E2%80%94FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>Vitis AI——FPGA学习笔记 | Switch</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/rss2.xml" title="Switch" type="application/rss+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Switch</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">27</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">41</span></a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/03/29/Vitis%20AI%E2%80%94%E2%80%94FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="SWQ">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Switch">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Vitis AI——FPGA学习笔记
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2024-03-29 17:29:19" itemprop="dateCreated datePublished" datetime="2024-03-29T17:29:19+08:00">2024-03-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2025-02-08 11:54:05" itemprop="dateModified" datetime="2025-02-08T11:54:05+08:00">2025-02-08</time>
              </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>21k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>19 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>参考资料：</p>
<p>[Xilinx&#x2F;Vitis-AI-Tutorials (github.com)](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-AI-">https://github.com/Xilinx/Vitis-AI-</a><br>Tutorials “Xilinx&#x2F;Vitis-AI-Tutorials (github.com)“)</p>
<p><a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-AI" title="Xilinx&#x2F;Vitis-
AI: Vitis AI is Xilinx’s development stack for AI inference on Xilinx hardware
platforms">Xilinx&#x2F;Vitis-AI: Vitis AI is Xilinx’s development stack for AI inference on<br>Xilinx hardware platforms</a></p>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1iR4y1k7wn/?spm_id_from=333.788&vd_source=01cde8042a76495bf513aa4407a56cd6" title="【03】ALINX Zynq UltraScale+ MPSoC XILINX FPGA视频教程Vitis AI开发">【03】ALINX Zynq UltraScale+ MPSoC XILINX FPGA视频教程Vitis<br>AI开发</a></p>
<h2 id="一-简介"><a href="#一-简介" class="headerlink" title="一. 简介"></a>一. 简介</h2><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h3><p>边缘计算edge-ai；cloud-computing-edge-computing</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/089f9efe7c54689a339a571239a84873.png"></p>
<p>edge端inference全栈部署方案</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/966474c137754c658fddaa07152e7ef2.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/319a2ebc600fdfb819856d52d5825acc.png"></p>
<h4 id="安装vitis-ai的准备"><a href="#安装vitis-ai的准备" class="headerlink" title="安装vitis-ai的准备"></a>安装vitis-ai的准备</h4><p>In addition, Vitis AI supports three host types（对于三种类型的机器，安装vitis-ai需做一定准备：</p>
<blockquote>
<blockquote>
<ul>
<li>CPU-only with no GPU acceleration：CPU hosts require no special<br>preparation.<blockquote>
<ul>
<li>CUDA-capable GPUs</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<ul>
<li>AMD ROCm™ GPUs：见[Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;install.rst.txt](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;blob&#x2F;master&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;install.rst.txt#id3 “Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;install.rst.txt”)</li>
</ul>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
</blockquote>
</blockquote>
<p>&lt;1&gt;安装docker、Clone github Repository：</p>
<pre><code>git clone https://github.com/Xilinx/Vitis-AI
cd Vitis-AI
</code></pre>
<p>注：You are now ready to start working with the Vitis AI Docker container. At<br>this stage you will choose whether you wish to <strong>use the pre-built container,<br>or build the container from scripts</strong>. docker环境的搭建可以选择Vitis-<br>ai中的脚本搭建或者docker官方直接下载<strong>预构建的</strong> 特定架构docker（见后），即：</p>
<pre><code>docker pull xilinx/vitis-ai-&lt;Framework&gt;-&lt;Arch&gt;:latest
</code></pre>
<table>
<thead>
<tr>
<th>Desired Docker</th>
<th><Framework></Framework></th>
<th><Arch></Arch></th>
</tr>
</thead>
<tbody><tr>
<td>PyTorch cpu-only</td>
<td>pytorch</td>
<td>cpu</td>
</tr>
<tr>
<td>TensorFlow 2 cpu-only</td>
<td>tensorflow2</td>
<td>cpu</td>
</tr>
<tr>
<td>TensorFlow 1.15 cpu-only</td>
<td>tensorflow</td>
<td>cpu</td>
</tr>
<tr>
<td>PyTorch ROCm</td>
<td>pytorch</td>
<td>rocm</td>
</tr>
<tr>
<td>TensorFlow 2 ROCm</td>
<td>tensorflow2</td>
<td>rocm</td>
</tr>
</tbody></table>
<p>或：</p>
<pre><code>cd &lt;Vitis-AI install path&gt;/Vitis-AI
./docker_run.sh xilinx/vitis-ai-&lt;pytorch|tensorflow2|tensorflow&gt;-&lt;cpu|rocm&gt;:latest
</code></pre>
<p>适用机器类型：</p>
<ol>
<li>CPU-only</li>
<li>CUDA-capable GPUs</li>
<li>ROCm-capable GPUs</li>
</ol>
<p>注：The <code>cpu</code> option <em>does not provide GPU acceleration support</em>  which is<br><strong>strongly recommended</strong>  for acceleration of the Vitis AI [:ref:<code>Quantization process &lt;quantization-process&gt;</code>](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;blob&#x2F;master&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;install.rst.txt#id11<br>“:ref:<code>Quantization process &lt;quantization-process&gt;</code> “). The pre-built <code>cpu</code><br>container should only be used when a GPU is not available on the host machine.</p>
<p>（原文详细介绍了在NVIDIA器件上支持CUDA GPU的vitis-ai搭建）</p>
<p>注：vitis-ai补丁安装：[Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;patch_instructions.rst.txt](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;blob&#x2F;master&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;patch_instructions.rst.txt “Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;patch_instructions.rst.txt”)</p>
<p>&lt;2&gt;安装交叉编译环境</p>
<p>By default, the<strong>cross compiler</strong> will be installed in<br><strong><code>~/petalinux_sdk_2023.1</code></strong>. The ~&#x2F;petalinux_sdk_2023.1 path is recommended<br>for the installation. Regardless of the path you choose for the installation,<br>make sure the path has read-write permissions. In this quickstart, it is<br>installed in ~&#x2F;petalinux_sdk_2023.1</p>
<p>在bash中执行：</p>
<pre><code>[Host] $ cd Vitis-AI/board_setup/vek280
[Host] $ sudo chmod u+r+x host_cross_compiler_setup.sh
[Host] $ ./host_cross_compiler_setup.sh
</code></pre>
<p>注：为下载相关资源，执行前的软件安装源为清华源，也可参考：[Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;China_Ubuntu_servers.](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;blob&#x2F;master&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;China_Ubuntu_servers.rst.txt “Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;install&#x2F;China_Ubuntu_servers.”)</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/93def47e1072cf25c9fb7e564d9ac777.png"></p>
<p> When the installation is complete, follow the prompts and execute the<br>following command:</p>
<pre><code>source ~/petalinux_sdk_2023.1/environment-setup-cortexa72-cortexa53-xilinx-linux
</code></pre>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/bc05d626369cb12f1b1b386fad291dfc.png"></p>
<pre><code>     The **DPU** implements **an efficient tensor-level instruction set **designed to support and **accelerate** various popular **convolutional neural networks** , such as VGG, ResNet, GoogLeNet, YOLO, SSD, and MobileNet, among others. 

    The DPU supports on AMD **Zynq™ UltraScale+™ MPSoCs, the Kria™ KV260, Versal™ and Alveo cards**. It scales to meet the requirements of many diverse applications in terms of throughput, latency, scalability, and power. 
</code></pre>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/acb9834ffdad75aafa209db3944d7929.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/b926c0530c9f863597c101da17b84dd2.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/7632c574e72b01f31355845825ac6439.png"></p>
<h5 id="Zynq-™-UltraScale-™-MPSoC-DPUCZDX8G-workflow-system"><a href="#Zynq-™-UltraScale-™-MPSoC-DPUCZDX8G-workflow-system" class="headerlink" title="Zynq ™ UltraScale+ ™ MPSoC: DPUCZDX8G([workflow-system-"></a>Zynq ™ UltraScale+ ™ MPSoC: DPUCZDX8G([workflow-system-</h5><p>integration.rst.txt at master](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;blob&#x2F;master&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;workflow-system-integration.rst.txt<br>“workflow-system-integration.rst.txt at master”)</p>
<p>The DPUCZDX8G IP has been optimized for Zynq UltraScale+ MPSoC. You can<br>integrate this IP as a block in the programmable logic (PL) of the selected<br>Zynq UltraScale+ MPSoCs with direct connections to the processing system (PS).<br>The DPU is user-configurable and exposes several parameters which can be<br>specified to optimize PL resources or customize enabled features.</p>
<p> 下载地址：</p>
<table>
<thead>
<tr>
<th>Product Guide</th>
<th>Platforms</th>
<th>Vitis AI Release</th>
<th>Reference Design</th>
<th>IP-only Download</th>
</tr>
</thead>
<tbody><tr>
<td>DPUCV2DX8G <a target="_blank" rel="noopener" href="https://docs.xilinx.com/r/en-US/pg425-dpu" title="PG425">PG425</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>VEK280&#x2F;V70&#x2F;Vx2802</td>
<td>3.5</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>[Download](<a target="_blank" rel="noopener" href="https://www.xilinx.com/bin/public/openDownload?filename=DPUCV2DX8G_VAI_v3.5.tar.gz">https://www.xilinx.com/bin/public/openDownload?filename=DPUCV2DX8G_VAI_v3.5.tar.gz</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>“Download”)</td>
<td>[Get</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IP](<a target="_blank" rel="noopener" href="https://www.xilinx.com/bin/public/openDownload?filename=DPUCV2DX8G_ip_repo_VAI_v3.5.tar.gz">https://www.xilinx.com/bin/public/openDownload?filename=DPUCV2DX8G_ip_repo_VAI_v3.5.tar.gz</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>“Get IP”)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DPUCV2DX8G <a target="_blank" rel="noopener" href="https://docs.xilinx.com/r/en-US/pg425-dpu" title="PG425">PG425</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>VE2302(see note)</td>
<td>3.5</td>
<td>[Early Access](<a target="_blank" rel="noopener" href="https://account.amd.com/en/member/vitis-">https://account.amd.com/en/member/vitis-</a></td>
<td></td>
<td></td>
</tr>
<tr>
<td>ai-ve2302.html “Early Access”)</td>
<td>[Early</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Access](<a target="_blank" rel="noopener" href="https://account.amd.com/en/member/vitis-ai-ve2302.html">https://account.amd.com/en/member/vitis-ai-ve2302.html</a> “Early Access”)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DPUCZDX8G <a target="_blank" rel="noopener" href="https://docs.xilinx.com/r/en-US/pg338-dpu" title="PG338">PG338</a></td>
<td>MPSoC &amp;</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Kria K26</td>
<td>3.0</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>[Download](<a target="_blank" rel="noopener" href="https://www.xilinx.com/bin/public/openDownload?filename=DPUCZDX8G_VAI_v3.0.tar.gz">https://www.xilinx.com/bin/public/openDownload?filename=DPUCZDX8G_VAI_v3.0.tar.gz</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>“Download”)</td>
<td>[Get</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IP](<a target="_blank" rel="noopener" href="https://www.xilinx.com/bin/public/openDownload?filename=DPUCZDX8G_ip_repo_VAI_v3.0.tar.gz">https://www.xilinx.com/bin/public/openDownload?filename=DPUCZDX8G_ip_repo_VAI_v3.0.tar.gz</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>“Get IP”)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>DPUCVDX8G <a target="_blank" rel="noopener" href="https://docs.xilinx.com/r/en-US/pg389-dpu" title="PG389">PG389</a></td>
<td>VCK190</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>3.0</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>[Download](<a target="_blank" rel="noopener" href="https://www.xilinx.com/bin/public/openDownload?filename=DPUCVDX8G_VAI_v3.0.tar.gz">https://www.xilinx.com/bin/public/openDownload?filename=DPUCVDX8G_VAI_v3.0.tar.gz</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>“Download”)</td>
<td>[Get</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>IP](<a target="_blank" rel="noopener" href="https://www.xilinx.com/bin/public/openDownload?filename=DPUCVDX8G_ip_repo_VAI_v3.0.tar.gz">https://www.xilinx.com/bin/public/openDownload?filename=DPUCVDX8G_ip_repo_VAI_v3.0.tar.gz</a></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>“Get IP”)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>For MPSoC and Versal AI Core (non AIE-ML devices) please refer to the**&#x2F;dpu**<br>subdirectory in the Vitis AI 3.0 Github repository.</p>
<p><strong>部署过程：</strong>[Vitis-AI-Tutorials&#x2F;Tutorials&#x2F;Vitis-AI-Vivado-TRD at 2.0 ·<br>Xilinx&#x2F;Vitis-AI-Tutorials (github.com)](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-AI-">https://github.com/Xilinx/Vitis-AI-</a><br>Tutorials&#x2F;tree&#x2F;2.0&#x2F;Tutorials&#x2F;Vitis-AI-Vivado-TRD “Vitis-AI-<br>Tutorials&#x2F;Tutorials&#x2F;Vitis-AI-Vivado-TRD at 2.0 · Xilinx&#x2F;Vitis-AI-Tutorials<br>(github.com)“)</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/959557dd80a7f6cf4d928cceb75051d3.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/0508c091f64853b67804b2e760e60cbb.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/3caf388ba1b35f2a14b2243c95dc133c.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/999d2443c9fa5ace609d9ea94ced32fa.png"></p>
<h3 id="2-实例"><a href="#2-实例" class="headerlink" title="2.实例"></a>2.实例</h3><p><img src="https://i-blog.csdnimg.cn/blog_migrate/7830ed03ef207f14e4a19700168625d9.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/fd38dd26c8c57234f377f0f7a4a2ef48.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/5558aa103e0c00df512de7552ebe3804.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/8bd66f3a8c93d2eb320e9af0f1109b3c.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/18e33f756df780499701f1488563de29.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/8913598ae8b0c899f6a709062fe876f9.png"></p>
<h3 id="3-vitis-ai的解决方案"><a href="#3-vitis-ai的解决方案" class="headerlink" title="3.vitis-ai的解决方案"></a>3.vitis-ai的解决方案</h3><p>The Vitis AI solution is packaged and delivered as follows:</p>
<ul>
<li>AMD open download: pre-built target <strong>images</strong> integrating the <strong>DPU</strong></li>
<li>Vitis AI <strong>docker containers</strong> : model development tools</li>
<li>Vitis AI <strong>github repository</strong> : model deployment libraries, setup scripts, examples and reference designs</li>
</ul>
<h3 id="4-vitis-ai工具链"><a href="#4-vitis-ai工具链" class="headerlink" title="4.vitis-ai工具链"></a>4.vitis-ai工具链</h3><p><strong>Model Development</strong><br><strong>Vitis AI Model Zoo</strong><br>The :ref:<code>Vitis AI Model Zoo &lt;workflow-model-zoo&gt;</code> includes <strong>optimized deep<br>learning models</strong> to speed up the deployment of deep learning inference on<br>adaptable AMD platforms. These models cover different applications, including<br>ADAS&#x2F;AD, video surveillance, robotics, and data center. You can get started<br>with these pre-trained models to enjoy the benefits of deep learning<br>acceleration.</p>
<p><strong>Vitis AI Model Inspector</strong><br>The :ref:<code>Vitis AI Model Inspector &lt;model-inspector&gt;</code> is used to <strong>perform<br>initial sanity checks</strong> to confirm that t<strong>he operators and sequence of<br>operators</strong> in the graph is compatible with Vitis AI. Novel neural network<br>architectures, operators, and activation types are constantly being developed<br>and optimized for prediction accuracy and performance. Vitis AI provides<br>mechanisms to leverage operators that are not natively supported by your<br>specific DPU target.</p>
<p><strong>Vitis AI Optimizer</strong><br>The :ref:<code>Vitis AI Optimizer &lt;model-optimization&gt;</code> exploits <strong>the notion of<br>sparsity</strong> to r<strong>educe the overall computational complexity</strong> for inference by<br>5x to 50x with minimal accuracy degradation. Many deep neural network<br>topologies employ significant levels of redundancy. This is particularly true<br>when the network backbone is optimized for prediction accuracy with training<br>datasets supporting many classes. In many cases, this redundancy can be<br>reduced by “pruning” some of the operations out of the graph.</p>
<p><strong>Vitis AI Quantizer</strong><br>The :ref:<code>Vitis AI Quantizer &lt;model-quantization&gt;</code>, integrated as a component<br>of either TensorFlow or PyTorch, <strong>converts 32-bit floating-point weights</strong><br>and activations to<strong>fixed-point integers like INT8</strong> to reduce the computing<br>complexity without losing prediction accuracy. The fixed-point network model<br>requires less memory bandwidth and provides faster speed and higher power<br>efficiency than the floating-point model.</p>
<p><strong>Vitis AI Compiler</strong><br>The :ref:<code>Vitis AI Compiler &lt;model-compilation&gt;</code> maps the AI quantized<br>model<strong>to a highly-efficient instruction set and dataflow model</strong>. The<br>compiler performs multiple optimizations; for example, batch normalization<br>operations are fused with convolution when the convolution operator precedes<br>the normalization operator. As the DPU supports <strong>multiple dimensions of<br>parallelism</strong> , efficient instruction scheduling is <strong>key to exploiting the<br>inherent parallelism</strong> and potential for <strong>data reuse</strong> in the graph. The<br>Vitis AI Compiler addresses such optimizations.</p>
<p><strong>Model Deployment<br>Vitis AI Runtime</strong><br>The :ref:<code>Vitis AI Runtime &lt;vitis-ai-runtime&gt;</code> (VART) is<strong>a set of low-level<br>API functions</strong> that support the integration of the DPU into software<br>applications. VART is built on top of the Xilinx Runtime (XRT) amd provides a<br>unified high-level runtime for both Data Center and Embedded targets. Key<br>features of the <strong>Vitis AI Runtime API</strong> include:</p>
<p>Asynchronous <strong>submission</strong> of <strong>jobs</strong> to the <strong>DPU</strong>.<br>Asynchronous <strong>collection</strong> of <strong>jobs</strong> from the <strong>DPU</strong>.<br><strong>C++ and Python API</strong> implementations.<br>Support for <strong>multi-threading and multi-process</strong> execution.<br><strong>Vitis AI Library</strong><br>The :ref:<code>Vitis AI Library &lt;vitis-ai-library&gt;</code> is a set of <strong>high-level<br>libraries and APIs built on top of the Vitis AI Runtime (VART)</strong>. The higher-<br>level APIs included in the Vitis AI Library give developers a head-start on<br>model deployment. While it is possible for developers to directly leverage the<br>Vitis AI Runtime APIs to deploy a model on AMD platforms, it is often more<br>beneficial to start with a ready-made example that incorporates the various<br>elements of a typical application, including:</p>
<p><strong>Simplified CPU-based pre and post-processing implementations.</strong><br>Vitis AI Runtime integration at an application level.<br><strong>Vitis AI Profiler</strong><br>The :ref:<code>Vitis AI Profiler &lt;vitis-ai-profiler&gt;</code> profiles and visualizes AI<br>applications to find <strong>bottlenecks</strong> and allocates computing resources among<br>different devices. It is easy to use and requires no code changes. It can<br><strong>trace function calls</strong> and <strong>run time</strong> , and also <strong>collect hardware<br>information</strong> , including CPU, DPU, and memory utilization.</p>
<p>模型开发：示例模型、检查器（语法、适用性）、优化器（稀疏连接）、量化器（位宽）、编译器（DPU指令）</p>
<p>模型部署：VART（DPU API）、Library（优化预处理、后处理）、分析器（各环节运行时间）</p>
<h2 id="二-Docker环境搭建"><a href="#二-Docker环境搭建" class="headerlink" title="二.Docker环境搭建"></a>二.Docker环境搭建</h2><p>在第一部分“安装的准备”已经介绍了搭建的两种方法。</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/32b5b070bc91e1a49bc4d0cf742becc9.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/d0f0f5995489ccc5498b68acb9a6ac56.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/3fde56db0b1e14a450d2f3f07ce98f82.png"></p>
<pre><code>sudo apt-get remove docker-engine docker-ce docker.io

sudo apt-get install curl

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo apt-get update &amp;&amp; sudo apt install docker-ce docker-ce-cll containerd.io

systemctl status docker

sudo docker run hello-world

sudo usermod -aG docker $USER

newgrp docker

docker run hello-world

docker info

docker images

docker ps -a
</code></pre>
<p>若安装docker-ce失败：</p>
<p><a target="_blank" rel="noopener" href="https://mirror.tuna.tsinghua.edu.cn/help/docker-ce/" title="docker-ce | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror">docker-ce | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror</a></p>
<p>下载vitis-ai的docker：</p>
<p><a target="_blank" rel="noopener" href="https://hub.docker.com/r/xilinx/vitis-ai-cpu" title="xilinx&#x2F;vitis-ai-cpu - Docker Image | Docker Hub">xilinx&#x2F;vitis-ai-cpu - Docker Image | Docker Hub</a></p>
<p><a target="_blank" rel="noopener" href="https://hub.docker.com/r/xilinx/vitis-ai" title="xilinx&#x2F;vitis-ai - Docker Image | Docker Hub">xilinx&#x2F;vitis-ai - Docker Image | Docker Hub</a></p>
<pre><code>docker pull xilinx/vitis-ai
</code></pre>
<p>使用git命令下载vitis-ai</p>
<pre><code>git clone https://github.com/Xilinx/Vitis-AI
</code></pre>
<p>启动docker环境：vitis-ai目录下运行脚本</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/17de1dceb4e74e034696eb3b16af2272.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/53bfce013f7c4c2e53486eb49cae2149.png"></p>
<p>可以看到其工作目录为workspace，上机目录直接为系统根目录：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/00f5736efd94ea115591a8121f7171b4.png"></p>
<p> 而且这个docker预装了conda，进入 tensorflow 的conda并打印其组件：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/1a916ce4ff8de0d37df1060bec900bd9.png"></p>
<p>其他docker命令：[Docker最新超详细版教程通俗易懂(基础版) - 知乎<br>(zhihu.com)](<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/442442997">https://zhuanlan.zhihu.com/p/442442997</a> “Docker最新超详细版教程通俗易懂(基础版)</p>
<ul>
<li>知乎 (zhihu.com)“)</li>
</ul>
<h2 id="三-实例"><a href="#三-实例" class="headerlink" title="三.实例"></a>三.实例</h2><h3 id="1-下载示例模型"><a href="#1-下载示例模型" class="headerlink" title="1.下载示例模型"></a>1.下载示例模型</h3><p>在model_zoo文件夹内可以浏览各种支持的模型，这里我们选择tf_yolov3_3.5，打开model_info.md文件：</p>
<pre><code># YOLOv3

### Contents
1. [Use Case and Application](#Use-Case-and-Application)
2. [Specification](#Specification)
3. [Paper and Architecture](#Paper-and-Architecture)
4. [Dataset Preparation](#Dataset-Preparation)
5. [Use Guide](#Use-Guide)
6. [License](#License)
7. [Note](#Note)


### Use Case and Application

   - Classic Object Detection
   - Trained on VOC dataset
   
   
### Specification

| Metric             | Value                                   |
| :----------------- | :-------------------------------------- |
| Framework          | TensorFlow2                             |
| Prune Ratio        | 0%                                      |
| FLOPs              | 65.63G                                  |
| Input Dims (H W C) | 416,416,3                               |
| FP32 Accuracy      | 0.7846 mAP                              |
| INT8 Accuracy      | 0.7729 mAP                              |
| Train Dataset      | voc07+12_trainval	                   |
| Test Dataset       | voc07_test                              |
| Supported Platform | GPU, VEK280, V70                        |
  

### Paper and Architecture 

1. Network Architecture: YOLOv3

2. Paper Link: https://arxiv.org/abs/1804.02767

   
### Dataset Preparation

1. Dataset description

The model is trained on VOC2007_trainval + VOC2012_trainval and tested on VOC2007_test.

2. Download and prepare the dataset

Our script `prepare_data.sh` downloads and prepares the dataset automatically. But if you have downloaded the VOC2007 test set before, you could place them in the `data` directory manually and choose to skip downloading the dataset when the script asking for a choice. Run the script: 
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash code/test/dataset_tools/prepare_data.sh</span><br></pre></td></tr></table></figure>
Dataset diretory structure
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">VOCdevkit is unpacked from the downloaded data</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">voc2007_test is generated by our code <span class="keyword">for</span> data preparation</span></span><br><span class="line">+ data</span><br><span class="line">  + VOCdevkit</span><br><span class="line">    + VOC2007</span><br><span class="line">      + ImageSets</span><br><span class="line">      + JPEGImages</span><br><span class="line">      + Annotations</span><br><span class="line">  + voc2007_test</span><br><span class="line">    + images</span><br><span class="line">      + 000001.jpg</span><br><span class="line">      + 000002.jpg</span><br><span class="line">      + ...</span><br><span class="line">    + test.txt</span><br><span class="line">    + gt_detection.txt</span><br></pre></td></tr></table></figure>


### Use Guide

1. Evaluation
    Configure the model path and data path in [code/test/run_eval.sh](code/test/run_eval.sh)
    <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash code/test/run_eval.sh</span><br></pre></td></tr></table></figure>
  
   
### License

Apache License 2.0

For details, please refer to **[Vitis-AI License](https://github.com/Xilinx/Vitis-AI/blob/master/LICENSE)**


### Note

1. Data preprocess
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data channel order: RGB(0~255)</span><br><span class="line">input = input / 255</span><br><span class="line">resize: keep aspect ratio of the raw image and resize it to make the length of the longer side equal to 416</span><br><span class="line">padding: pad along the short side with 0.5 to generate the input image with size = 416 x 416</span><br></pre></td></tr></table></figure>
2. Node information

  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input node: &#x27;input_1:0&#x27;</span><br><span class="line">output nodes: &#x27;conv2d_59/BiasAdd:0&#x27;, &#x27;conv2d_67/BiasAdd:0&#x27;, &#x27;conv2d_75/BiasAdd:0&#x27;</span><br></pre></td></tr></table></figure>
  

### Quantize

1. Quantize tool installation

   Please refer to [vai_q_tensorflow](../../../src/vai_quantizer/vai_q_tensorflow1.x)
  
2. Quantize workspace

   You could use code/quantize/ folder.
</code></pre>
<p><strong>详细阅读该文件介绍，接下来下载所需文件：</strong></p>
<p>在model_zoo文件夹，运行downloader.py，下载tf_yolov3_3.5</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/c9a7d62a708af32a1de4b5d1c059a76e.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/13689caf7d2c1dcba28ba1b59e594a71.png"></p>
<p> 下载后对文件进行解压：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/154c0219b2383c095a676e4a40d64715.png"></p>
<p>通常model-zoo提供的模型文件结构如下：</p>
<p>tensorflow：</p>
<pre><code>├── code                            # Contains test code that can execute the model on the target and showcase model performance.
│
│
├── readme.md                       # Documents the environment requirements, data pre-processing requirements, and model information.
│                                     Developers should refer to this to understand how to test the model with scripts.
│
├── data                            # The dataset target directory that can be used for model verification and training.
│                                     When test or training scripts run successfully, the dataset will be placed in this directory.
│
├── quantized
│   └── quantize_eval_model.pb      # Quantized model for evaluation.
│
└── float
    └── frozen.pb                   # The floating-point frozen model is used as the input to the quantizer.
                                      The naming of the protobuf file may differ from the model naming used in the model list.
</code></pre>
<p>pytorch：</p>
<pre><code>├── code                            # Contains test and training code.
│
│
├── readme.md                       # Contains the environment requirements, data pre-processing requirements and model information.
│                                     Developers should refer to this to understand how to test and train the model with scripts.
│
├── data                            # The dataset target directory that is used for model verification and training.
│                                     When test or training scripts run successfully, the dataset will be placed in this directory.
│
├── qat                             # Contains the QAT (Quantization Aware Training) results.
│                                     For some models, the accuracy of QAT is higher than with Post Training Quantization (PTQ) methods.
│                                     Some models, but not all, provide QAT reference results, and only these models have a QAT folder.
│
├── quantized
│   ├── _int.pth                    # Quantized model.
│   ├── quant_info.json             # Quantization steps of tensors got. Please keep it for evaluation of quantized model.
│   ├── _int.py                     # Converted vai_q_pytorch format model.
│   └── _int.xmodel                 # Deployed model. The name of different models may be different.
│                                     For some models that support QAT you could find better quantization results in &#39;qat&#39; folder.
│
│
└── float
    └── _int.pth                    # Trained float-point model. The pth name of different models may be different.
                                      Path and model name in test scripts could be modified according to actual situation.
</code></pre>
<p>打开下载好的tf_yolov3_3.5文件夹，其中按照之前的model_info文件所叙述的内容，进行“Download and prepare the<br>dataset”（不是必须运行）：</p>
<pre><code>bash code/test/dataset_tools/prepare_data.sh
</code></pre>
<p>下载好的文件结构也在md文件中，在docker中执行评估（不是必须运行）（docker外需配置环境cv2、numpy）：</p>
<pre><code>bash code/test/run_eval.sh
</code></pre>
<p>评估结果：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/38b92c92fb4b1a06262e88117770e500.png"></p>
<p>安装snap和snapcraft后安装模型查看工具netron：</p>
<pre><code>sudo apt-get install snap
sudo apt-get install snapcraft
sudo snap install netron
</code></pre>
<p>然后就可以查看float文件夹下的pb文件网络的结构：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/4a57b4d4b3f8c4bcd95910f16c04e505.png"></p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/a5c9e1dc7906295e163c8989b3a3b743.png"></p>
<pre><code>1. Data preprocess
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data channel order: RGB(0~255)</span><br><span class="line">input = input / 255</span><br><span class="line">resize: keep aspect ratio of the raw image and resize it to make the length of the longer side equal to 416</span><br><span class="line">padding: pad along the short side with 0.5 to generate the input image with size = 416 x 416</span><br></pre></td></tr></table></figure>
2. Node information

  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input node: &#x27;input_1:0&#x27;</span><br><span class="line">output nodes: &#x27;conv2d_59/BiasAdd:0&#x27;, &#x27;conv2d_67/BiasAdd:0&#x27;, &#x27;conv2d_75/BiasAdd:0&#x27;</span><br></pre></td></tr></table></figure>
 
</code></pre>
<p>可以看到在第59、67、75个conv2d节点后进行了输出：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/030fa826ada83d08a466bb23919680bc.png"></p>
<h3 id="2-模型量化"><a href="#2-模型量化" class="headerlink" title="2.模型量化"></a>2.模型量化</h3><p>在上述md文件最后给出了量化指引：</p>
<pre><code>### Quantize

1. Quantize tool installation

   Please refer to [vai_q_tensorflow](../../../src/vai_quantizer/vai_q_tensorflow1.x)
  
2. Quantize workspace

   You could use code/quantize/ folder.
</code></pre>
<p>量化参考vitis-ai文件夹下src…和code&#x2F;quantize&#x2F;里的内容</p>
<p>在code&#x2F;quantize&#x2F;中的config.ini是配置文件，包括量化后模型名、存放位置为&#x2F;quantized及各种参数；</p>
<p>打开quantize.sh脚本，关注以下内容：</p>
<pre><code>source ./config.ini

vai_q_tensorflow quantize \
  --input_frozen_graph $FLOAT_MODEL \
  --input_nodes $Q_INPUT_NODE \
  --input_shapes ?,$INPUT_HEIGHT,$INPUT_WIDTH,3 \
  --output_nodes $Q_OUTPUT_NODE \
  --input_fn $CALIB_INPUT_FN \
  --method $METHOD \
  --gpu $GPUS \
  --calib_iter $CALIB_ITER \
  --output_dir $QUANTIZE_DIR \
</code></pre>
<p>可以看到在量化过程中其调用config.ini中的各种参数，然后通过src&#x2F;vai_quantizer&#x2F;vai_q_tensorflow1.x工具进行量化，转到对应位置，在readme文件中可以看到详细信息：</p>
<p>[Vitis-AI&#x2F;src&#x2F;vai_quantizer&#x2F;vai_q_tensorflow1.x at master · Xilinx&#x2F;Vitis-AI<br>(github.com)](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;tree&#x2F;master&#x2F;src&#x2F;vai_quantizer&#x2F;vai_q_tensorflow1.x “Vitis-<br>AI&#x2F;src&#x2F;vai_quantizer&#x2F;vai_q_tensorflow1.x at master · Xilinx&#x2F;Vitis-AI<br>(github.com)“)</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/9d34d43f9036308c8f83f589b763afd2.jpeg"></p>
<pre><code>#目的：
The process of inference is computation intensive and requires a high memory bandwidth to satisfy the low-latency and high-throughput requirement of edge applications.

#介绍（vitis-ai工具只包含量化工具，修建工具在optimizer中）：
Quantization and channel pruning techniques are employed to address these issues while achieving high performance and high energy efficiency with little degradation in accuracy. Quantization makes it possible to use integer computing units and to represent weights and activations by lower bits, while pruning reduces the overall required operations. In the Vitis AI quantizer, only the quantization tool is included. The pruning tool is packaged in the Vitis AI optimizer. Contact the support team for the Vitis AI development kit if you require the pruning tool.
</code></pre>
<p>将32位浮点数转化为8位整数：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/b4e03ee0be4436f378980db2d44681b1.jpeg"></p>
<p>量化的步骤：</p>
<pre><code>## Running vai_q_tensorflow
### Preparing the Float Model and Related Input Files
|1|frozen_graph.pb|Floating-point frozen inference graph. Ensure that the graph is the inference graph rather than the training graph.|
|2|calibration dataset|A subset of the training dataset containing 100 to 1000 images.|
|3|input_fn|An input function to convert the calibration dataset to the input data of the frozen_graph during quantize calibration. Usually performs data pre-processing and augmentation.|
#### **Generating the Frozen Inference Graph**
Training a model with TensorFlow 1.x creates a folder containing a GraphDef file (usually ending with *a.pb* or *.pbtxt* extension) and a set of checkpoint files. What you need for mobile or embedded deployment is a single GraphDef file that has been “frozen,” or had its variables converted into inline constants, so everything is in one file. To handle the conversion, TensorFlow provides *freeze_graph.py*, which is automatically installed with the vai_q_tensorflow quantizer.
#### **Preparing the Calibration Dataset and Input Function**
The calibration set is usually a subset of the training/validation dataset or actual application images (at least 100 images for performance). The input function is a Python importable function to load the calibration dataset and perform data preprocessing. The vai_q_tensorflow quantizer can accept an input_fn to do the preprocessing, which is not saved in the graph. If the preprocessing subgraph is saved into the frozen graph, the input_fn only needs to read the images from dataset and return a feed_dict.
### Quantizing the Model Using vai_q_tensorflow
### Generating the Quantized Model
- *quantize_eval_model.pb* is used to evaluate the CPU/GPUs, and can be used to simulate the results on hardware.
|1|deploy_model.pb|Quantized model for the Vitis AI compiler (extended TensorFlow format) for targeting DPUCZDX8G implementations.|
|2|quantize_eval_model.pb|Quantized model for evaluation (also, the Vitis AI compiler input for most DPU architectures, like DPUCAHX8H, and DPUCADF8H).|
### (Optional) Fast Finetune
Fast finetune adjusts the weights layer by layer with calibration dataset and may get better accuracy for some models. It will take much longer time than normal PTQ (still shorter than QAT as calibration dataset is much smaller than train dataset) and is disabled by default to save time, and can be turned on to try to improve the performance if you see accuracy issues.
### (Optional) Exporting the Quantized Model to ONNX
The quantized model is tensorflow protobuf format by default. If you want to get a ONNX format model, just add *output_format* to the *vai_q_tensorflow* command.
### (Optional) Evaluating the Quantized Model
If you have scripts to evaluate floating point models, like the models in [Vitis AI Model Zoo](https://github.com/Xilinx/Vitis-AI/tree/master/model_zoo), apply the following two changes to evaluate the quantized model:...
### (Optional) Dumping the Simulation Results

## vai_q_tensorflow Quantization Aware Training
Quantization aware training (QAT, also called *quantize finetuning* in [Quantization Overview](#quantization-overview)) is similar to float model training/finetuning, but in QAT, the vai_q_tensorflow APIs are used to rewrite the float graph to convert it to a quantized graph before the training starts. The typical workflow is as follows:...
### Generated Files
### QAT APIs for TensorFlow 1.x

## Converting to Float16 or BFloat16
The vai_q_tensorflow supports data type conversions for float models, including Float16, BFloat16, Float, and Double. To achieve this, you can add *convert_datatype* to the vai_q_tensorflow command. 

## vai_q_tensorflow Supported Operations and APIs
</code></pre>
<p> 在准备阶段包括：推理图的固化（freeze_graph.py已安装在vai_q_tensorflow内）、准备验证数据集和输入函数…</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/2035fe160556f3713512b51266287de1.png"></p>
<p>关于vai_q_tensorflow命令的详细使用见readme中的vai_q_tensorflow Usage，例：</p>
<pre><code>#show help: 
$vai_q_tensorflow --help

#quantize:
$vai_q_tensorflow quantize --input_frozen_graph frozen_graph.pb \
--input_nodes inputs \
--output_nodes predictions \
--input_shapes ?,224,224,3 \
--input_fn my_input_fn.calib_input

#dump quantized model:
$vai_q_tensorflow dump --input_frozen_graph quantize_results/quantize_eval_model.pb \
--input_fn my_input_fn.dump_input
</code></pre>
<p>将 &#x2F;float&#x2F;文件夹下的fb文件重命名为float.fb，在docker环境中转到&#x2F;quantize文件夹下运行量化脚本（下载包含运行后文件，非必要）：</p>
<pre><code>bash quantize.sh
</code></pre>
<p>运行结果如下：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/d38f0ab41704bb97f91f371d5b4c3cfd.png"></p>
<p>量化后的模型文件位于&#x2F;quantize的pb文件，继续运行&#x2F;quantize下的evaluate_quantize_model.sh文件（非必要）对量化后的模型进行评估，结果如下：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/4c32c7a9a74429a18ef81f04ae3638c1.png"></p>
<h3 id="3-模型编译"><a href="#3-模型编译" class="headerlink" title="3.模型编译"></a>3.模型编译</h3><h2 id="四-mpsoc快速开始"><a href="#四-mpsoc快速开始" class="headerlink" title="四.mpsoc快速开始"></a>四.mpsoc快速开始</h2><p>见：[Vitis-AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;quickstart&#x2F;mpsoc.rst.txt at v3.5 ·<br>Xilinx&#x2F;Vitis-AI (github.com)](<a target="_blank" rel="noopener" href="https://github.com/Xilinx/Vitis-">https://github.com/Xilinx/Vitis-</a><br>AI&#x2F;blob&#x2F;v3.5&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;quickstart&#x2F;mpsoc.rst.txt “Vitis-<br>AI&#x2F;docs&#x2F;_sources&#x2F;docs&#x2F;quickstart&#x2F;mpsoc.rst.txt at v3.5 · Xilinx&#x2F;Vitis-AI<br>(github.com)“)</p>
<p>（适合xilinx官方开发板zcu102、zcu104、kv260）</p>
<h2 id="五-官方资料"><a href="#五-官方资料" class="headerlink" title="五.官方资料"></a>五.官方资料</h2><p>vivado_integration：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/6c5bf2b5b0093972699eb12988ab59d9.png"></p>
<p>vitis_integration：</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/478de52c0e6c34207461eb523f74eb5a.png"></p>
<p>vek280_setup:</p>
<p><img src="https://i-blog.csdnimg.cn/blog_migrate/781bf68946aadd0ca2d81fe1be31e3f9.png"></p>
<p>本文转自 <a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_32971095/article/details/136803363">https://blog.csdn.net/qq_32971095/article/details/136803363</a>，如有侵权，请联系删除。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>SWQ
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://example.com/2024/03/29/Vitis%20AI%E2%80%94%E2%80%94FPGA%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" title="Vitis AI——FPGA学习笔记">http://example.com/2024/03/29/Vitis AI——FPGA学习笔记/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wechat_channel.jpg">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </a>
        </div>

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/fpga%E5%BC%80%E5%8F%91/" rel="tag"># fpga开发</a>
              <a href="/tags/%E5%AD%A6%E4%B9%A0/" rel="tag"># 学习</a>
              <a href="/tags/%E7%AC%94%E8%AE%B0/" rel="tag"># 笔记</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2024/03/29/AI%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="prev" title="AI学习笔记">
      <i class="fa fa-chevron-left"></i> AI学习笔记
    </a></div>
      <div class="post-nav-item">
    <a href="/2024/04/03/%E8%A5%BF%E7%94%B5%E8%AE%A1%E7%A7%91%E5%A4%A7%E4%B8%89%E4%B8%8BSOC%E5%BE%AE%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%E8%AE%BE%E8%AE%A1%E4%BD%9C%E4%B8%9A%E5%90%88%E9%9B%86/" rel="next" title="西电计科大三下SOC微体系结构设计作业合集">
      西电计科大三下SOC微体系结构设计作业合集 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%80-%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">一. 简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E7%AE%80%E4%BB%8B"><span class="nav-number">1.1.</span> <span class="nav-text">1.简介</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%89%E8%A3%85vitis-ai%E7%9A%84%E5%87%86%E5%A4%87"><span class="nav-number">1.1.1.</span> <span class="nav-text">安装vitis-ai的准备</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#Zynq-%E2%84%A2-UltraScale-%E2%84%A2-MPSoC-DPUCZDX8G-workflow-system"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">Zynq ™ UltraScale+ ™ MPSoC: DPUCZDX8G([workflow-system-</span></a></li></ol></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E5%AE%9E%E4%BE%8B"><span class="nav-number">1.2.</span> <span class="nav-text">2.实例</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-vitis-ai%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="nav-number">1.3.</span> <span class="nav-text">3.vitis-ai的解决方案</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-vitis-ai%E5%B7%A5%E5%85%B7%E9%93%BE"><span class="nav-number">1.4.</span> <span class="nav-text">4.vitis-ai工具链</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C-Docker%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-number">2.</span> <span class="nav-text">二.Docker环境搭建</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89-%E5%AE%9E%E4%BE%8B"><span class="nav-number">3.</span> <span class="nav-text">三.实例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-%E4%B8%8B%E8%BD%BD%E7%A4%BA%E4%BE%8B%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.1.</span> <span class="nav-text">1.下载示例模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-%E6%A8%A1%E5%9E%8B%E9%87%8F%E5%8C%96"><span class="nav-number">3.2.</span> <span class="nav-text">2.模型量化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-%E6%A8%A1%E5%9E%8B%E7%BC%96%E8%AF%91"><span class="nav-number">3.3.</span> <span class="nav-text">3.模型编译</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9B%9B-mpsoc%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B"><span class="nav-number">4.</span> <span class="nav-text">四.mpsoc快速开始</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%94-%E5%AE%98%E6%96%B9%E8%B5%84%E6%96%99"><span class="nav-number">5.</span> <span class="nav-text">五.官方资料</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="SWQ"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">SWQ</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">41</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">27</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/xidianswq" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;xidianswq" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/3209507800@qq.com" title="E-Mail → 3209507800@qq.com"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/qq_32971095" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;qq_32971095" rel="noopener" target="_blank"><i class="fa fa-link fa-fw"></i>CSDN</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; Sat Feb 08 2025 08:00:00 GMT+0800 (中国标准时间) – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SWQ</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">站点总字数：</span>
    <span title="站点总字数">790k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
      <span class="post-meta-item-text">站点阅读时长 &asymp;</span>
    <span title="站点阅读时长">11:58</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> 强力驱动
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">总访问量<span id="busuanzi_value_site_pv"></span>次</span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">总访客数<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
<!-- 不蒜子计数初始值纠正 -->
<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);  // 50ms周期检测函数
    var countOffset = 20000;  // 初始化首次数据

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset); // 加上初始数据 
            clearInterval(int); // 停止检测
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>


  <script defer src="/lib/three/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>


  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
